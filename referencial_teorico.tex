% referencial_teorico.tex

\pagebreak
\chapter{Referencial teórico}
\index{Referencial Teórico}
\thispagestyle{fancy}

\section{Recuperação de informação}
\index{Recuperação de informação}

Um \gls{sri} é um sistema capaz de armazenar, obter e dar manutenção em informações \cite[p. 2]{kowalski}. Nesse contexto,informação pode ser composto por texto, imagens, áudio, vídeo e outros objetos multimídia.

Um \gls{sri} consiste em um programa de software que facilita a busca de informação por um usuário. O grau de sucesso de um \gls{sri} é relacionado no quanto o mesmo diminui a burocracia (\gls{overhead}) para o usuário encontrar uma informação. O sucesso de um SRI é muito subjetivo e baseia-se em qual informação o usuário quer e sua predisposição a enfrentar ou não a burocracia do processo \cite[p. 4]{kowalski}

\subsection{SRIs para Web}
\index{Recuperação de informação!SRIs para Web}

Comparado com SRIs clássicos, os SRIs para Web encara um conjunto de dados totalmente diferentes \cite[p. 2]{surveyir}. Segundo \cite{surveyir}, dentre os motivos que tornam únicos os SRIs para Web, pode-se citar:

\begin{itemize}
	\item \textbf{Internet Dinâmica} - A Internet muda a cada dia enquanto a maioria dos SRIs clássicos é feita para bancos de dados estáticos.
	\item \textbf{Heterogenidade} - A Internet contém uma grande variedade de tipos de documentos: figuras, arquivos de áudio, textos, scripts, etc.
	\item \textbf{Variedade de línguas} - O número de línguas diferentes na Internet passa de 100.
	\item \textbf{Duplicação} - A cópia é uma outra característica importante da Web: há estimativas de que a quantidade de conteúdo copiado chega a 30\% \cite{surveyir}.
	\item \textbf{Alto número de links} - Em média, cada documento tem mais que 8 links para outras páginas.
	\item \textbf{Consultas heterogêneas} - SRIs para Web têm que lidar com pequenas consultas e não necessariamente bem representadas dos usários de Internet.
	\item \textbf{Grande variância de usuários} - Cada usuário da Web é diferente em vista das suas necessidades, resultados esperados e conhecimento.
	\item \textbf{Comportamento específicos} - É estimado que cerca de 85\% consideram somente a primeira página dos resultados retornados dos motores de busca. 78\% dos usuários nunca modificam seu primeiro termo de consulta.
\end{itemize}

Sendo assim, é possível concluir que o grande desafio de SRIs para Web é suprir as necessidades de informação dos usuários dado que há grande heterogenidade na Web.

\subsection{Motores de busca de propósito geral}
\index{Recuperação de informação!SRIs para Web!Motores de busca de propósito geral}
%verificar se está numerando as subseções

Dentre os motores de busca de propósito geral mais utilizados, há o Google, o Bing e o AltaVista. Dentre os principais objetivos de um motor de busca de propósito geral destacam-se: 

\begin{itemize}
	\item Resultados de qualidade, independentemente da consulta utilizada.
	\item Uma boa cobertura dos documentos disponíveis na Web.
	\item Facilidade de uso.
	\item Ser flexível quanto ao tipo de mídia e documento a serem pesquisados.
\end{itemize}

Todos os serviços citados anteriormente estão de acordo com as necessidades supracitadas. Devido à natureza destes motores de busca, é difícil buscar por somente uma informação específica, como "Altura em centímetros do Michael Jordan". O máximo que esses motores podem fazer é retornar uma página que possa conter essa informação, não a informação em si.


\subsection{Motores de busca de domínio específico}
\index{Recuperação de informação!SRIs para Web!Motores de busca de domínio específico}

Ao contrário dos motores de busca de propósito geral, que buscam informações em sites sem distinção, os motores de busca de domínio específico buscam por informações específicas em sites específicos. Tais motores de busca podem ser utilizados para suprir a necessidade de precisão que se perde com os motores de busca de propósito geral, fornecendo ao usuário resultados mais completos, relevantes e/ou específicos.

Motores de busca de domínio específico estão se tornando populares porque oferecem uma melhor precisão com recursos extras que não são possíveis com motores de busca de propósito geral \cite[p. 8]{wober}.

Um outro problema dos grandes motores de busca é sua falha em manter índices atualizados, devido ao fato de haver um vasto número de páginas que precisam ser indexadas. Um motor de busca de propósito específico possui um conjunto menor de páginas para indexar e consequentemente pode atualizá-las mais frequentemente, o que leva a resultados mais atualizados para os usuários.

A funcionalidade extra se refere à apresentação de interfaces mais sofisticadas para usuários que são configurados para um domínio particular de busca. Desde que todos os usuários visitando uma busca de domínio específico pertecem a um grupo de pessoas com interesses e desejos similares, a busca específica por domínio pode utilizar mais efetivamente o perfil do usuário para dar recomendações mais precisas quando o mesmo tiver dificuldades de especificar suas necessidades \cite[p. 9]{wober}.
% não ficou bom a partir de "Desde"

\subsection{Busca semântica}

A Web semântica é uma extensão da web atual em que a informação dada possui significado bem definido, permitindo que os computadores e pessoas possam trabalhar em cooperação \cite[p. 13]{wober}. Esse novo formato da \gls{www} tem como visão ser tão capaz  quanto a \gls{www} atual, mas consiste em dados legíveis por máquina, que possui o potencial para ter um maior impacto na busca na web.


Na prática, o ''significado bem definido das informações'' é alcançado com o uso de metadados nas páginas Web. \emph{Tags} HTML como \texttt{<title>} e \texttt{<meta>} possuem grande valor no processo de definição de significado da página. Outros fatores como URLs semânticas auxiliam nesse processo também.

Apesar do RDF e do XML estarem se tornando amplamente reconhecidos como veículo padrão para a descrição de metadados, uma enorme parcela de dados semânticos ainda reside dentro de documentos HTML \cite[p. 14]{wober}.

\pagebreak
\section{Python}
\index{Python}

\hyphenation{a-tri-bu-tos}

Segundo \cite{pythondoc}, o Python é uma linguagem poderosa, de propósitos gerais, fácil de aprender e programar, interpretada, orientada a objetos e com alguns outros atributos que a tornam uma linguagem ideal para \emph{scripting} e desenvolvimento rápido de aplicações.

\subsection{Histórico}
\index{Python!Historico}

A linguagem Python foi criada no início dos anos 1990 por Guido Van Rossum \cite{pythonlicense}, no \emph{Stichting Mathematisch Centrum}, na Holanda, com o intuito de ser uma linguagem substituta ao ABC, que apresentava uma série de problemas, especialmente com extensibilidade \cite{pythonfaq}. A linguagem Python, inicialmente, foi criada para ser uma substituta da linguagem ABC, mantendo os poderes de sua API.

Van Rossum permanece como o principal autor da linguagem Python, apesar de receber várias contribuições de colaboradores externos.

Um erro comum é associar a origem o nome da linguagem Python com o nome da serpente. De fato, Van Rossum se inspirou num grupo de comediantes britânicos, o Monty Python, para dar nome à linguagem \cite{pythonfaq} .

\subsection{Características}
\index{Python!Caracteristicas}
Qualidade de software, produtividade do programador, portabilidade, bibliotecas de suporte, integração de componentes e diversão são os principais motivos do uso da linguagem \cite[p. 48,49]{learningpython}. 

Em seu modelo, a linguagem Python implementa uma sintaxe deliberadamente simples e legível e um modelo de programação coerente \cite[p. 50]{learningpython}. 

Dentre as razões históricas, a linguagem Python foi concebida no início da década de 1990, quando ocorreu o \emph{boom} da Internet e quando o número de programadores se tornou escasso para a demanda de software. Enquanto linguagens de baixo nível como Assembly ou C priorizam a \emph{produtividade de máquina}, Python prioriza a \emph{produtividade do programador}. 

Python é otimizada para produtividade do programador. Recursos como sintaxe simples, tipagem dinâmica, não necessidade de compilação e um conjunto de ferramentas embutidas permitem que programadores desenvolvam programas em uma fração de tempo necessária em comparação a quando usam outras ferramentas \cite[p. 50]{learningpython}. 

Entretanto, existe um \gls{tradeoff} no uso da linguagem Python: a velocidade de execução. Programadores tendem a ser mais produtivos com o uso de linguagens com os atributos que Python possui. Porém, o código Python não é um código de máquina, portanto o mesmo precisa ser interpretado a cada execução, o que o torna mais lento. 

Outros fatores como a tipagem dinâmica tendem a trazer mais \gls{overhead} na execução dos programas em Python, degradando ainda mais sua velocidade de execução, e seu uso difícil ou inviável para projetos que dependam estritamente de velocidade de execução (ex: componentes de baixo nível, como Kernels e drivers de dispositivos, aplicativos de produtividade, como suítes de escritórios e CAD e outros softwares de grande porte).

\subsubsection{Tipagem dinâmica}
\index{Python!Ambientes e plataformas!Tipagem Dinâmica}

A tipagem dinâmica é uma propriedade de uma linguagem de programação que permite que a checagem de tipo seja feito em tempo de execução, ao contrário da tipagem estática, onde a verificação de tipo é feita em tempo de compilação.


Segundo \cite{dynamic_langs}, as principais vantagens ao se utilizar uma linguagem de tipagem dinâmica é evitar a rigidez de linguagens estaticamente tipadas, tornar mais fácil a prototipação de sistemas que possuem requisitos ainda não conhecidos ou que mudam de uma forma não previsível, aumentar o reuso de código, diminuir a verbosidade e o custo do projeto, sem necessariamente ser menos seguras que as linguagens de tipagem estática.

Devido ao seu baixo nível de burocracia e alto poder de prototipação, as linguagens dinâmicas são freqüentemente para integração entre componentes \cite{scripting}. Por esse motivo, as linguagens dinâmicas também são conhecidas por \emph{linguagens-cola} ou \emph{linguagens de integração de sistemas}.

Uma linguagem que não é apegada a tipos permite que a integração entre componentes seja bem mais fácil, pois não há restrições primárias sobre como os retornos de cada componente devam ser utilizados: todos eles são apresentados de uma única forma \cite{scripting}.

Linguagens dinâmicas, como o Python, são ideais para pesquisas e provas de conceito, graças a seu alto poder de prototipação, o que ajuda a explicar o quão Python está em uso na comunidade científica, como demonstrado em \cite{python_scientific_world}.

\subsection{Ambientes e plataformas}
\index{Python!Ambientes e plataformas}

Python é uma linguagem portável e multiplataforma. Isso significa que um código em Python pode ser executado nos mais diversos ambientes e sistemas operacionais, como Windows, Linux, Mac OS e em até sistemas operacionais móveis como Symbian e Android.

Há também a possibilidade de executar a linguagem Python em outros ambientes diferentes do original (CPython). Iniciativas como Jython (Python para a \emph{Java Virtual Machine}) e o IronPython (Python para o ambiente Microsoft.NET) permitem que o Python seja executado dentro das duas das maiores plataformas de desenvolvimento de software da atualidade, aproveitando seus recursos e suas funcionalidades. Dessa forma, um programa em Python pode utilizar o Swing\footnote{Swing é uma interface de programação de aplicativos Java para interfaces gráficas} através do Jython para o desenvolvimento de uma interface gráfica em ambiente Java ou pode utilizar o \emph{Windows Communication Foundation} como \emph{framework} de troca de mensagens no ambiente Microsoft.NET.

\subsubsection{CPython}
\index{Python!Ambientes e plataformas!IronPython}

O CPython é a implementação padrão da linguagem Python e é escrita na linguagem de programação C \cite[p.6]{pypy}. A linguagem é implementada por um compilador que traduz código Python em um código código-objeto de altíssimo nível (\emph{very high level}) e por uma máquina virtual que interpreta o código.

\subsubsection{IronPython}
\index{Python!Ambientes e plataformas!IronPython}

O IronPython \cite{ironpython} é uma implementação da linguagem de programação Python que é executada no framework .NET e Silverlight. Suporta um \gls{shell} interativo (como a maioria das implementações da linguagem Python) com compilação dinâmica. É integrado com o resto do framework .NET e torna todas as bibliotecas do .NET disponíveis para programadores Python, enquanto mantém a compatibilidade com a linguagem Python.

\subsubsection{Jython}
\index{Python!Ambientes e plataformas!Jython}

Jython \cite{jython} é uma implementação da linguagem Python para a JVM (\emph{Java Virtual Machine}). O Jython torna possível a execução da sintaxe da linguagem de programação Python na plataforma Java, o que permite uma integração transparente com as bibliotecas Java e outras aplicações baseadas em Java. 

\subsubsection{PyPy}
\index{Python!Ambientes e plataformas!PyPy}

PyPy é uma implementação do Python escrita em Python \cite[p. 7]{pypy}. A idéia principal é escrever uma especificação de alto nível do interpretador em um subtrato restrito do Python chamado RPython (\emph{Restricted Python}) com o intuito de ser traduzido para executáveis eficientes de baixo nível para o ambiente C/POSIX, \gls{jvm} e \Gls{cli}, o que garante a portabilidade. 

\subsection{Python e Computação Científica}
\index{Python!Python e Computação Científica}

Segundo \cite{python_scientific_world}, Python e estensões como o NumPy \cite{numpy} estão se tornando padrão para muitas ciências que precisam processar grande quantidades de dados, desde a neuroimagem à astronomia.

Conferências anuais especificamente voltadas para usos de Python em computação científica, como o SciPy \cite{scipy} (tanto na versão norte-americana quanto na européia) vem ganhando mais representatividade a cada ano.

Ambientes de desenvolvimento integrado como o PythonXY \cite{pythonxy} ajudam a mostrar para cientistas que a linguagem Python com seus pacotes de bibliotecas e softwares para computação científica pode ser uma excelente alternativa para ambientes como o Matlab \footnote{\url{http://www.mathworks.com/products/matlab/}}. 

Um dos casos mais famosos da linguagem Python para os sistemas de recuperação de informações é o Google\cite{google}. Ela representa um papel fundamental dentro da estrutura de motores de busca do Google, sendo responsável pelos seus \emph{crawlers} e pelos seus servidores de URL \cite{surveyir}.

\pagebreak
\section{Scrapy}
\index{Scrapy}

Scrapy é um framework rápido e de alto nível para \gls{screenscraping} e \gls{crawling}, usado para navegar por websites e extrair dados estruturados de suas páginas. Pode ser usado para um grande número de propósitos, desde mineração de dados a monitoramento e automação de testes \cite{scrapy}. Mesmo que o Scrapy tenha sido originalmente feito para \gls{screenscraping}, ele também pode ser utilizado para extrair dados usando APIs (como as APIs de serviços da Amazon\footnote{\url{http://www.amazon.com/webservices}}) ou pode ser utilizado como um \gls{webcrawler} de propósito geral.

Dentre as principais funcionalidades que o Scrapy apresenta, podem-se citar:

\begin{itemize}
	\item Suporte embutido para selecionar e extrair dados de fontes em HTML ou XML.
	\item Suporte embutido para limpeza e sanitização dos dados obtidos utilizando uma coleção de filtros reutilizáveis (chamados de \emph{Item Loaders}) compartilhados entre todos os \glspl{webcrawler}.
	\item Suporte embutido para geração e exportação de \glspl{feed} em múltiplos formatos e armazenamento dos mesmos (seja em FTP ou localmente).
	\item Um gerenciador de mídia para download automático de imagens (ou qualquer outro tipo de mídia) associado com os itens obtidos.
	\item Suporte para extensão do Scrapy, sendo possível adicionar funcionalidades ao framework através do uso de sinais e uma API bem definida.
	\item Grande quantidade de \glspl{middleware} e extensões para gerenciamento de cookies e sessões, compressão HTTP, autenticação HTTP, cache HTTP, mudança do header \emph{user-agent} \footnote{\Gls{httpheader}} que identifica o navegador do cliente e restrições sobre a profundidade de \gls{crawling}.
	\item Suporte robusto para auto-detecção de codificação, assim como manipulação de codificações estrangeiras, quebradas e fora dos padrões.
	\item Extensa coleção de status para métricas do \gls{webcrawler}, úteis para monitoramento de performance e de disponibilidade.
	\item Um console interativo para teste de \glspl{xpath}, útil para \gls{debugging}.
	\item Um serviço a nível de sistema feito para facilitar a implantação e execução dos crawlers em produção.
	\item \Glspl{webservice} e console telnet embutidos para monitoração, controle, introspecção e \gls{debugging} do crawler.
\end{itemize}

\subsection{Arquitetura}
\index{Scrapy!Arquitetura}

O diagrama demonstrado na figura \ref{scrapy_architecture} apresenta uma visão geral da arquitetura do Scrapy com seus componentes e o fluxo de dados que há dentro do sistema (mostrado em setas verdes). A seguir, cada um dos componentes, bem como o fluxo de dados serão descritos.

\begin{figure} [ht]
	\centering
	\includegraphics[scale=1]{scrapy_architecture.png}
	\caption{Visão geral da arquitetura do scrapy \cite{scrapy_arch}}
	\label{scrapy_architecture}
\end{figure}

\subsubsection{\emph{Scrapy engine}}
\index{Scrapy!Arquitetura!Scrapy engine}

O \emph{engine} é responsável por controlar o fluxo de dados entre todos os componentes do sistema, e disparar eventos quando certas ações ocorrerem.

\subsubsection{\emph{Scheduler} (agendador)}
\index{Scrapy!Arquitetura!Scheduler}

O \emph{scheduler} (agendador) recebe requisições do \emph{engine} e as enfileira para a realimentação da engine no futuro.

\subsubsection{\emph{Downloader}}
\index{Scrapy!Arquitetura!Downloader}

O \emph{Downloader} é responsável por obter páginas da Web e alimentar o \emph{engine}, que por sua vez alimenta os crawlers/spiders.

\subsubsection{Item pipeline}
\index{Scrapy!Arquitetura!Item pipeline}

O \textit{Item Pipeline} é responsável pelo processamento dos itens uma vez que eles foram extraídos pelos \textit{crawlers}/\textit{spiders}. Tarefas típicas do \textit{Item Pipeline} incluem limpeza, validação e persistência do item.

\subsubsection{Spider middlewares}
\index{Scrapy!Arquitetura!Spider middlewares}

\emph{Spider} \glspl{middleware} fica entre a \emph{Engine} e os \emph{Spiders} e podem processar a entrada de um sipder (respostas) e saídas (itens e requisições). Eles fornecem um mecanismo conveniente para estender as funcionalidades do Scrapy através da adição de código customizado.

\subsubsection{Scheduler middlewares}
\index{Scrapy!Arquitetura!Scheduler middlewares}

\emph{Scheduler} \glspl{middleware} fica entre a \emph{Engine} e o \emph{Scheduler} e processa requisições quando as mesmas passam do \textit{engine} para o \textit{Scheduler} e vice-versa. Eles fornecem um mecanismo conveniente para estender as funcionalidades do Scrapy através da adição de código customizado.

\subsubsection{Fluxo de dados}
\index{Scrapy!Arquitetura!Fluxo de dados}

O fluxo de dados do Scrapy é controlado pela Engine e funciona da seguinte forma:

\begin{enumerate}
	\item O \emph{Engine} abre um domínio, localiza o \emph{Spider} que manipula aquele domínio e pede para o \emph{Spider} a primeira URL para navegar.
	\item O \emph{Engine} pega a primeira URL para navegar do Spider e a agenda no Scheduler como Requisições.
	\item O \emph{Engine} pede para o \emph{Scheduler} as próximas URLs para navegar.
	\item O \emph{Scheduler} retorna a próxima URL para navegação para o \emph{Engine} e este a envia para o \emph{Downloader} passando pelo \emph{Downloader Middleware}.
	\item Uma vez que o download da página terminou, o Downloader gera uma Resposta (\emph{Response}) (com a página) e a manda para o \emph{Engine}, passando pelo \emph{Downloader Middleware}.
	\item O \textit{Engine} recebe a resposta do \textit{Downloader} e a envia para o \textit{Spider} processar, passando pelo \textit{Spider Middleware}.
	\item O \textit{Spider} processa a Resposta (\textit{Response}) e retorna os itens obtidos e novas Requisições(\textit{Requests}) para o \textit{Engine}.
	\item O \textit{Engine} envia os itens obtidos (retornados pelo \textit{spider}) para o \textit{Item Pipeline} e envia as Requisições(retornadas pelo \textit{Spider}) para o \textit{Scheduler}.
	\item O processo se repete a partir do passo 2 até que não existam mais Requisições no \textit{Scheduler} e o \textit{Engine} fecha o domínio.
\end{enumerate}

\subsubsection{E/S orientado a eventos}
\index{Scrapy!Arquitetura!Networking orientado a eventos}

O Scrapy é escrito utilizando o Twisted \cite{twisted}, um \textit{framework} popular para programação orientada a eventos para Python. Desta forma, ele é implementado utilizado código não-bloqueante (ou assíncrono) para aumentar a concorrência.

\subsection{Serviços embutidos}
\index{Scrapy!Serviços embutidos}

O Scrapy possui uma gama de serviços embutidos implementados para facilitar a monitoração e a manutenção do sistema. A seguir, são apresentados cada um destes serviços embutidos.

\subsubsection{\textit{Logging}}
\index{Scrapy!Serviços embutidos!Logging}

O \textit{log} é um histórico de execução do sistema. Através da análise de logs, é possível detectar e achar a fonte de problemas. O Scrapy possui um componente de \textit{logging} que grava as mensagens de log em um arquivo em disco e possui cinco níveis de log \cite{scrapy_log}:

\begin{enumerate}
	\item \texttt{\textbf{CRITICAL}} - Para erros críticos
	\item \texttt{\textbf{ERROR}} - Para erros regulares
	\item \texttt{\textbf{WARNING}} - Para avisos
	\item \texttt{\textbf{INFO}} - Para mensagens informativas
	\item \texttt{\textbf{DEBUG}} - Para mensagens de debug
\end{enumerate}

O nível de log é configurável e um determinado nível irá catalogar todas as mensagens do nível mais as mensagens dos níveis abaixo. Por exemplo, se o nível de log for configurado para 5 (\texttt{DEBUG}), o sistema irá gravar todas as mensagens de log, ao passo que se o nível de log for configurado para 2 (\texttt{ERROR}), somente as mensagens de erros regulares e erros críticos serão gravadas.

\subsection{Código fonte}

O Scrapy é um \emph{framework} de código aberto, disponível em um repositório no Github (\url{http://github.com/}) no endereço \url{http://github.com/insophia/scrapy/}.

\pagebreak
\section{Git e Github}

Git é um sistema de controle de versões distribuído escrito inicialmente por Linus Torvalds, criador do kernel do Linux e atualmente mantido por Junio Hamano \cite{progit}.

\subsection{Controle de versões}

Um controle de versões é um sistema que guarda modificações a um arquivo ou conjunto de arquivos com o passar do tempo, com o principal intuito de obter versões específicas a qualquer momento \cite[p. 1]{progit}.


\subsubsection{Controle local de versões}

Segundo \cite[p.2]{progit}, é comum pessoas controlarem versões manualmente através da cópia de arquivos para outras pastas, provavelmente com alguma indicação de data, como ilustrado na Figura \ref{local_version_control}. Apesar de simples, esse sistema de versionamento é propenso a erros devido ao fato que se vale da memória humana para encontrar versões específicas e controlar alterações.

\begin{figure} [ht]
	\centering
	\includegraphics[scale=0.4]{local_version_control.png}
	\caption{Diagrama de um controle de versões locais \cite[p. 1]{progit}}
	\label{local_version_control}
\end{figure}

Com o passar do tempo, pequenos e simples sistemas de controle de versão com banco de dados locais para guardar listas de alterações foram criados para ajudar a resolver esse problema.

\subsubsection{Controle de versões centralizado}

O maior problema com controle de versões locais é a dificuldade de colaboração \cite[p. 3]{progit}. Para lidar com esse problema, sistemas de controle de versão centralizados, ilustrados na Figura \ref{central_version_control}, foram criados. Esses sistemas, como o CVS, Subversion e Perforce, possuem um único servidor que contém todos os arquivos versionados e um número de clientes que acessam os arquivos de um repositório central.

\begin{figure} [ht]
	\centering
	\includegraphics[scale=0.4]{central_version_control.png}
	\caption{Diagrama de um controle de versões locais \cite[p. 2]{progit}}
	\label{central_version_control}
\end{figure}

Apesar de permitir a colaboração, há várias desvantagens com esta abordagem, principalmente no que diz respeito ao acesso: se o servidor que guarda estas informações sofrer um problema, ninguém poderá colaborar em um projeto ou salvar as últimas alterações (\emph{commit}) feitas.

\subsubsection{Controle de versões distribuído}

Os sistemas de controle de versões distribuídos, ilustrados na Figura \ref{dist_version_control}, ao invés de apenas obter apenas as últimas versões dos arquivos de um servidor central, uma cópia completa do repositório é copiada para a máquina local \cite[p. 4]{progit}. Dentre exemplos de sistemas de controle de versão distribuídos, pode-se citar o Git, Mercurial, Bazaar e Darcs.

\begin{figure} [ht]
	\centering
	\includegraphics[scale=0.4]{dist_version_control.png}
	\caption{Diagrama de um controle de versões distribuído \cite[p. 4]{progit}}
	\label{dist_version_control}
\end{figure}

Com sistemas de controle de versão distribuídos podem haver servidores centrais, mas a queda ou desconexão não impede a colaboração, já que, como todos os usuários de um determinado repositório possuem uma cópia completa do repositório localmente, eles podem trocar informações entre si sem maiores problemas \cite[p. 4]{progit}.

\subsection{Uma breve história do Git}

O Git surgiu da necessidade de criar um sistema de controle de versões para substituir o BitKeeper, um sistema de controle de versões distribuídos, devido à problemas com a empresa que o desenvolvia \cite[p. 5]{progit}. Alguns objetivos do novo sistema de controle de versões do kernel foram:

\begin{itemize}
	\item Velocidade.
	\item Design simples.
	\item Forte suporte para desenvolvimento não-linear (milhares de \emph{branches} - Ramificações).
	\item Totalmente distribuído.
	\item Habilidade para gerenciar grandes projetos, como o kernel do Linux, eficientemente. 
\end{itemize}


Segundo \cite{progit}, desde 2005, o Git evoluiu e se tornou maduro para ser fácil, mantendo as qualidades iniciais e sendo incrivelmente rápido, muito eficiente com projetos grandes e possui um sistema de \emph{branching} para desenvolvimento não-linear.

\subsection{Arquitetura do Git}

A seguir, são apresentados os itens mais relevantes no que diz respeito à arquitetura do Git.

\subsubsection{\emph{Snapshots} ao invés de diffs}

Uma das maiores diferenças entre o Git e outros Sistemas de Controle de Versão (SCM), como o Subversion e o Mercurial, é a forma como o Git trata os dados \cite[p. 6]{progit}. Esses sistemas tratam as informações como uma série de mudanças (deltas ou diffs) ao longo do tempo, como ilustrado na Figura \ref{scm_delta}:

\begin{figure} [ht]
	\centering
	\includegraphics[scale=0.5]{scm_delta.png}
	\caption{Diagrama que ilustra como outros sistemas tratam informações ao longo do tempo\cite[p. 6]{progit}}
	\label{scm_delta}
\end{figure}

O Git trata as informações como se fossem \emph{snapshots} de um pequeno sistema de arquivos. Segundo \cite[p. 6]{progit} o Git basicamente "tira uma foto" de como os arquivos estão toda vez que um \emph{commit}, ou o salvamento do estado do projeto no Git.

\pagebreak

\section{\emph{Website Parse Template}}
\index{Website Parse Template}


Website Parse Template (WPT) é um formato aberto baseado em XML que fornece informações adicionais a web crawlers como estrutura e conteúdo do HTML. O WPT é compatível com esquemas XML, como o RDF e o OWL \cite{wpt}. É composto por três seções principais:

\begin{itemize}
	\item \textbf{Templates} - Seção mandatória, que contém descrições sobre estrutura e conteúdo de páginas da web em HTML.
	\item \textbf{Ontologia} - Seção opcional que define conceitos e relações usadas em um website.
	\item \textbf{URLs} - Seção opcional, que associa certos padrões de URL para grupos de páginas web para templates específicos. 
\end{itemize}

Cada uma das seções do WPT apresentadas acima será discutida a seguir.

\subsection{Seções do WPT}
\index{Website Parse Template!Seções do WPT}

\subsubsection{Templates}
\index{Website Parse Template!Seções do WPT}

A seção de templates descreve a estrutura do HTML fazendo referências aos elementos HTML correspondentes da página em específico \cite{wpt}.

O Template inicia com a tag \texttt{<ow:template>} e termina com  \texttt{</ow:template>}. É obrigatório especificar um nome de template único dentro da tag \texttt{<ow:template>} e definir a URL correspondente ao template específico. O Template é composto de blocos correspondentes a cada elemento estrutural de uma página web em específico. Cada template precisa ter ao menos um bloco. Um bloco faz referência ao elemento HTML apropriado através de uma ou muitas combinações dos seguintes métodos de referência: TagID, XPath e Pattern. Cada bloco precisa iniciar com uma tag \texttt{<ow:block>} e fechar com \texttt{</ow:block>}. É necessário indicar elementos HTML específicos dentro da tag de abertura do bloco, como demonstrado na Listagem \ref{wpt_exemplo_template_tres_blocos}.

\pagebreak
\lstset{language=XML,
basicstyle=\scriptsize,
caption={Exemplo de um Template com três blocos \cite{wpt}},
captionpos=b
}
\begin{lstlisting}[label=wpt_exemplo_template_tres_blocos]
<ow:template ow:name="Template Example" ow:url="http://www.example.com/index.php">
  <ow:block ow:tagid="ex1" ow:xpath="/html/body/div/div" ow:pattern="content (object[[a-z]*])">
    <!--descricao do conteudo -->
  </ow:block>
  <ow:block ow:tagid="ex2">
    <!-- descricao do conteudo -->
  </ow:block>
  <ow:block ow:xpath="/html/body/div/div/table/tr[1]/td">
    <!-- descricao do conteudo -->
  </ow:block>
</ow:template>
\end{lstlisting}

Cada bloco contém a descrição do conteúdo dos elementos HTML representados isoladamente ou dentro de outro bloco. Blocos embutidos são usados para descrever elementos HTML específicos ("bloco pai") que incluem um ou mais elementos ("bloco filho"),como demonstrado na Listagem \ref{wpt_blocos_embutidos}.

\lstset{language=XML,
basicstyle=\scriptsize,
caption={Exemplo de um Template com blocos embutidos \cite{wpt}},
captionpos=b
}
\begin{lstlisting}[label=wpt_blocos_embutidos]
<ow:template ow:name="Template Example" ow:url="http://www.example.com/index.php">

  <ow:block ow:xpath="/html/body/div/div">
    <ow:block ow:xpath="/html/body/div/div/table/tbody/tr[1]/td">
      <!-- descricao do conteudo -->
    </ow:block>
  </ow:block>
  
</ow:template>
\end{lstlisting}

A descrição do conteúdo pode ser informada usando conceitos definidos na seção \emph{Ontology} ou qualquer linguagem/formato suportado: RDF, CWL, etc. É necessário declarar \textit{namespaces} dos esquemas XML usados dentro da tag \texttt{<ow:wpt>} e o nome da ontologia dentro da tag \texttt{<ow:template>}, como mostrado na Listagem \ref{wpt_descricao_conteudo}.

\pagebreak
\lstset{language=XML,
basicstyle=\scriptsize,
caption={Exemplo de um Template com instâncias de descrição de conteúdo\cite{wpt}},
captionpos=b
}
\begin{lstlisting}[label=wpt_descricao_conteudo]
<ow:wpt xmlns:ow="http://www.omfica.org/schemas/ow/0.9"
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 ow:host="http://www.example.com">

  <ow:template ow:name="Template Example" ow:url="http://www.example.com/index.php"
   ow:ontology="ontology_example">

     <!-- descricao de conteudo utilizando conceitos definidos -->
     <ow:block ow:tagid="ex1" ow:xpath="/html/body/div/div" ow:pattern="Wellcome (user.name[[A-Za-z]*])">
       conceito_de_ontologia
     </ow:block>
     <!-- descricao de conteudo utilizando a sintaxe RDF -->
     <ow:block ow:tagid="ex2">
       <rdf:Description rdf:about="http://www.example.com/index.php">
       </rdf:Description>
     </ow:block>
     <!-- descricao de conteudo utiliznado CWL.unl -->
     <ow:block ow:xpath="/html/body/div/div/table/tr[1]/td">
       {cwl.unl}
       {/cwl.unl}
     </ow:block>
  </ow:template>

</ow:wpt>
\end{lstlisting}

\subsubsection{URLs}
\index{Website Parse Template!URLs}

Essa seção define as URLS/padrões de URLs das páginas web descritas na seção de Templates. É mandatória se os templates não definem as URLs/padrões de URL das páginas web \cite{wpt}.

De acordo com a seção de Templates, essa seção também pode consistir de vários blocos/unidades. Cada um desses blocos iniciam com a tag \texttt{<ow:urls>} e terminam com a tag \texttt{</ow:urls>}, como mostrado na Listagem \ref{wpt_exemplo_padroes_urls}.


\lstset{language=XML,
basicstyle=\scriptsize,
caption={Exemplo de padrões de URLs \cite{wpt}},
captionpos=b,
label="wpt_url_pattern"
}
\begin{lstlisting}[label=wpt_exemplo_padroes_urls]
<ow:urls ow:name="Artist page on Yahoo! Music" ow:template="Artist page on Yahoo! Music">
  <ow:url>http://music.yahoo.com/ar-8206256---Amy-Winehouse</ow:url>
  <ow:url>http://music.yahoo.com/ar-([artist.id[0-9]*])---(artist.name[[A-Za-z0-9-]*])</ow:url>
</urls>
\end{lstlisting}

Especificações utilizando expressões regulares (RegExp) são utilizadas para descrição de padrões de URL. O padrão de URL informado na listagem \ref{wpt_exemplo_padroes_urls} também inclui a real URL representada. Os conceitos necessários para definição de padrões de URL (tais como "id" e "nome") são definidos na seção Ontology.

\subsubsection{\textit{Ontology}}
\index{Website Parse Template!URLs}

A seção \textit{Ontology} contém enumerações e definições de todos os conceitos utilizados no sítio \cite{wpt}. Os conceitos listados precisam ser definidos dentro das tags \texttt{<ow:ontology>} e \texttt{<ow:ontology>}, como mostrado na Listagem \ref{wpt_exemplo_ontology}. É necessário especificar o nome da ontologia dentro da tag \texttt{<ow:ontology>}. O WPT permite tanto o uso de OWL ou da \emph{WPT Ontology language} para definição de conceitos. A principal diferença dentre essas línguas é que a \emph{WPT Ontology language} fornece uma sintaxe simplificada para conceitos e definição de relações.

\lstset{language=XML,
basicstyle=\scriptsize,
caption={Definição conceitual de ''artista'' utilizando a \emph{WPT Ontology language} \cite{wpt}},
captionpos=b,
}
\begin{lstlisting}[label=wpt_exemplo_ontology]
<ow:ontology ow:name="general">
  <ow:concept ow:name="artist">
    <ow:inherit>person</ow:inherit>
    <ow:has>name</ow:has>
    <ow:has>album</ow:has>
    <ow:has>track</ow:has>
    <ow:has>image</ow:has>
    <ow:has>bio</ow:has>
    <ow:has>video</ow:has>
    <ow:has>id</ow:has>
  </ow:concept>
  <ow:concept>logo</ow:concept>
  <ow:concept>menu</ow:concept>
  <ow:concept>advertisement</ow:concept>
</ow:ontology>
\end{lstlisting}

Cada definição de conceito inicia com a tag \texttt{<ow:concept>} e termina com a tag\texttt{</ow:concept>}. A tag \texttt{<ow:inherit>} representa relações de herança e a tag \texttt{<ow:has>} representa relações atribuíveis entre dois conceitos. Os conceitos definidos tem um atributo padrão - identificador de objeto (id) para ser utilizado por \glspl{webcrawler} para coordenar os mesmos atributos do objeto utilizados em páginas diferentes do mesmo website.
