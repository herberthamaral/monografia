% justificativa
\chapter{Justificativa}

Recuperação de Informações na Web é uma tarefa fácil, porém trabalhosa se feita manualmente por humanos. Fácil, pois conseguimos detectar padrões de informações, categoriza-las e armazena-las como quisermos. Trabalhosa, pois podem haver inúmeras páginas com grandes quantidades de informação, o que torna o processo de recuperação manual de informações caro, trabalhoso e tedioso.

Soluções computacionais como \emph{web crawlers} ou \emph{web scrapers} ajudam na automação do processo de recuperação de informações estruturadas. 

No entanto, por serem soluções computacionais, demandam que sejam programadas e, geralmente, para um fim específico. Um \emph{web scraper} que foi originalmente desenvolvido para extrair informações de um determinado tipo de página, não conseguirá extrair as mesmas informações se a estrutura e/ou organização da página mudarem.

Na prática, um \emph{web scraper} projetado para um sítio, precisará sofrer modificações de forma que consiga extrair informações caso a estrutura da página em HTML mude, seja por uma mudança na estrutura de páginas do sítio ou pelo uso de um novo sítio que possa prover as mesmas informações.

Com a recuperação de informações de forma manual, havia o problema da falta de automação de processo, o que pode levar a um alto custo humano de recuperação de informações. Com a automação do processo, pode haver o problema de alto custo de criação e manutenção dos softwares responsáveis pela recuperação de informação estruturada.

O presente trabalho visa criar um método que diminua os custos de criação e manutenção de \emph{web scrapers} por meio da criação automatizada destes softwares através do uso de \emph{templates} em XML.

\section{XML e WPT}

Para o contexto deste trabalho, o XML desempenha um papel fundamental, onde as regras do \emph{web scraper} serão definidas para posterior geração do código do software de recuperação de informações em si.

O formato XML utilizado é o WPT (Website Parse Template)\cite{wpt}. O principal motivo para utiliza-lo é fazer uso de padrões Web já estabelecidos e documentados que descrevam a estrutura de páginas HTML.

Com isso, o XML se torna uma \emph{DSL} (\emph{Domain Specific Language} - Linguagem Específica de um Domínio) que é dedicada para o domínio de \emph{web scraping}. O uso de \emph{DSLs} faz com que não seja estritamente necessário codificar em uma linguagem de domínio geral, o que torna a tarefa específica de criação e manutenção de \emph{web scrapers} mais fácil e produtiva.

\section{Python}

A produtividade inerente à linguagem Python combinado com seu poder de prototipação, permite que \emph{web scrapers} sejam desenvolvidos e testados mais rapidamente.

O shell interativo (\emph{REPL - Read and Eval Print Loop}) disponível na distribuição da linguagem Python permite a criação e execução instantânea de código, sem precisar passar por passos como criação de arquivo com o código-fonte, linkagem e compilação.

Há também um histórico da linguagem Python para tarefas de recuperação de informação, como o motor de busca do Google, que possui vários componentes escritos em Python \cite{google}.

\section{Scrapy}

O framework de \emph{web scraping} Scrapy, escrito em Python, é um dos poucos disponíveis no mercado. Ele permite a criação de projetos de \emph{web scrapers} profissionais, com uma maior produtividade e organização.

A arquitetura do Scrapy permite que o projeto ganhe uma maior escala facilmente, tanto no âmbito de tamanho de projeto quanto na escalabilidade de recursos computacionais. Ele é construído usando o Twisted \cite{twisted}, uma engine de comunicação para redes e orientado a eventos, que possibilita a realização de operações de I/O não bloqueantes e, consequentemente, um modelo de concorrência sem uso de threads. 

Esta característica é vital, pois \emph{web scrapers} dependem de várias operações de I/O em rede para recuperação das páginas Web. Sem os recursos de I/O orientada à eventos, múltiplos processos do Python precisariam ser utilizados para haver concorrência, uma vez que a implementação original da linguagem não possui threads a nível de Kernel \cite{python_threads}.

